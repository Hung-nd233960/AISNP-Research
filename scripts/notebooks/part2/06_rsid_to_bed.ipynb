{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34cf7782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/Plutonium/Documents/BioinfoMidterm\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set project root\n",
    "project_root = Path(\"/home/Plutonium/Documents/BioinfoMidterm\")\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"scripts\"))\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Part 2 imports\n",
    "from part2.rsid_utils import (\n",
    "    load_rsid_list,\n",
    "    rsid_to_bed,\n",
    "    batch_rsid_lookup\n",
    ")\n",
    "\n",
    "# Project imports\n",
    "from config import PATHS\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99539a0a",
   "metadata": {},
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06605fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known AISNPs directory: /home/Plutonium/Documents/BioinfoMidterm/data/known_aisnps\n",
      "Output directory: /home/Plutonium/Documents/BioinfoMidterm/output/part2\n",
      "\n",
      "Found 1 rsID files:\n",
      "  - forenseq_ancestry.csv\n"
     ]
    }
   ],
   "source": [
    "# Input/Output directories\n",
    "KNOWN_AISNPS_DIR = project_root / \"data\" / \"known_aisnps\"\n",
    "OUTPUT_DIR = project_root / \"output\" / \"part2\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Known AISNPs directory: {KNOWN_AISNPS_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# List available rsID files\n",
    "if KNOWN_AISNPS_DIR.exists():\n",
    "    rsid_files = list(KNOWN_AISNPS_DIR.glob(\"*.csv\")) + list(KNOWN_AISNPS_DIR.glob(\"*.txt\"))\n",
    "    print(f\"\\nFound {len(rsid_files)} rsID files:\")\n",
    "    for f in rsid_files:\n",
    "        print(f\"  - {f.name}\")\n",
    "else:\n",
    "    print(\"\\nNo rsID files found. Please add files to data/known_aisnps/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d1d97",
   "metadata": {},
   "source": [
    "## Step 1: Define Known AISNP Sources\n",
    "\n",
    "Add your rsID sources here. Each source should have:\n",
    "- `name`: Short identifier\n",
    "- `file`: Path to rsID file\n",
    "- `description`: Source description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb5d70d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ forenseq: forenseq_ancestry.csv\n",
      "\n",
      "Available sources: 1/1\n"
     ]
    }
   ],
   "source": [
    "# Define known AISNP sources\n",
    "# Add your sources here\n",
    "SOURCES = [\n",
    "    # {\n",
    "    #     'name': 'kidd_55',\n",
    "    #     'file': KNOWN_AISNPS_DIR / 'kidd_55_aisnps.csv',\n",
    "    #     'description': 'Kidd et al. 55 AISNPs panel'\n",
    "    # },\n",
    "    # {\n",
    "    #     'name': 'precision_id',\n",
    "    #     'file': KNOWN_AISNPS_DIR / 'precision_id_ancestry.csv',\n",
    "    #     'description': 'ThermoFisher Precision ID Ancestry Panel'\n",
    "    # },\n",
    "    {\n",
    "        'name': 'forenseq',\n",
    "        'file': KNOWN_AISNPS_DIR / 'forenseq_ancestry.csv',\n",
    "        'description': 'Verogen ForenSeq Ancestry SNPs'\n",
    "    },\n",
    "    # Add more sources as needed\n",
    "]\n",
    "\n",
    "# Check which sources exist\n",
    "available_sources = []\n",
    "for source in SOURCES:\n",
    "    if source['file'].exists():\n",
    "        available_sources.append(source)\n",
    "        print(f\"✓ {source['name']}: {source['file'].name}\")\n",
    "    else:\n",
    "        print(f\"✗ {source['name']}: File not found - {source['file']}\")\n",
    "\n",
    "print(f\"\\nAvailable sources: {len(available_sources)}/{len(SOURCES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47933aaf",
   "metadata": {},
   "source": [
    "## Step 2: Load and Preview rsID Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8dae71f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Source: forenseq\n",
      "Description: Verogen ForenSeq Ancestry SNPs\n",
      "============================================================\n",
      "Loaded 56 rsIDs from /home/Plutonium/Documents/BioinfoMidterm/data/known_aisnps/forenseq_ancestry.csv\n",
      "First 10 rsIDs: ['rs2814778', 'rs3737576', 'rs7554936', 'rs10497191', 'rs1834619', 'rs1876482', 'rs260690', 'rs3827760', 'rs6754311', 'rs798443']\n",
      "Last 5 rsIDs: ['rs4891825', 'rs7226659', 'rs7251928', 'rs310644', 'rs2024566']\n"
     ]
    }
   ],
   "source": [
    "# Load and preview each source\n",
    "rsid_data = {}\n",
    "\n",
    "for source in available_sources:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Source: {source['name']}\")\n",
    "    print(f\"Description: {source['description']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    rsids = load_rsid_list(source['file'])\n",
    "    rsid_data[source['name']] = rsids\n",
    "    \n",
    "    print(f\"First 10 rsIDs: {rsids[:10]}\")\n",
    "    print(f\"Last 5 rsIDs: {rsids[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff76d3",
   "metadata": {},
   "source": [
    "## Step 3: Convert rsIDs to BED Format\n",
    "\n",
    "Uses Ensembl REST API to lookup genomic coordinates for each rsID.\n",
    "Results are cached to avoid repeated API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "395a5955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: forenseq\n",
      "============================================================\n",
      "Looking up 56 rsIDs...\n",
      "Loaded 56 cached entries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Looking up rsIDs: 100%|██████████| 56/56 [00:00<00:00, 599186.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache saved to /home/Plutonium/Documents/BioinfoMidterm/output/part2/forenseq_rsid_cache.csv\n",
      "Successfully resolved 56/56 rsIDs\n",
      "BED file saved: /home/Plutonium/Documents/BioinfoMidterm/output/part2/forenseq.bed\n",
      "Annotated CSV saved: /home/Plutonium/Documents/BioinfoMidterm/output/part2/forenseq_annotated.csv\n",
      "\n",
      "\n",
      "Generated BED files:\n",
      "  - forenseq: /home/Plutonium/Documents/BioinfoMidterm/output/part2/forenseq.bed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert each source to BED format\n",
    "# Using GRCh37 (hg19) to match 1000 Genomes Phase 3\n",
    "ASSEMBLY = 'GRCh37'\n",
    "\n",
    "bed_files = {}\n",
    "\n",
    "for source in available_sources:\n",
    "    name = source['name']\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    output_bed = str(OUTPUT_DIR / f\"{name}.bed\")\n",
    "    \n",
    "    bed_path = rsid_to_bed(\n",
    "        rsids=rsid_data[name],\n",
    "        output_path=output_bed,\n",
    "        assembly=ASSEMBLY,\n",
    "        source_name=name\n",
    "    )\n",
    "    \n",
    "    bed_files[name] = bed_path\n",
    "\n",
    "print(f\"\\n\\nGenerated BED files:\")\n",
    "for name, path in bed_files.items():\n",
    "    print(f\"  - {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f3d01",
   "metadata": {},
   "source": [
    "## Step 4: Verify BED Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fd201f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "forenseq:\n",
      "  Resolved: 56/56\n",
      "  Chromosome distribution:\n",
      "chr\n",
      "chr2     7\n",
      "chr13    5\n",
      "chr15    5\n",
      "chr17    5\n",
      "chr18    4\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Total_rsIDs</th>\n",
       "      <th>Resolved</th>\n",
       "      <th>Success_Rate</th>\n",
       "      <th>Chromosomes</th>\n",
       "      <th>BED_File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forenseq</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>100.0%</td>\n",
       "      <td>22</td>\n",
       "      <td>/home/Plutonium/Documents/BioinfoMidterm/outpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Source  Total_rsIDs  Resolved Success_Rate  Chromosomes  \\\n",
       "0  forenseq           56        56       100.0%           22   \n",
       "\n",
       "                                            BED_File  \n",
       "0  /home/Plutonium/Documents/BioinfoMidterm/outpu...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verify and summarize BED files\n",
    "summary = []\n",
    "\n",
    "for name, bed_path in bed_files.items():\n",
    "    # Load BED\n",
    "    bed_df = pd.read_csv(bed_path, sep='\\t', header=None,\n",
    "                         names=['chr', 'start', 'end', 'rsid'])\n",
    "    \n",
    "    # Load annotated CSV\n",
    "    csv_path = bed_path.replace('.bed', '_annotated.csv')\n",
    "    \n",
    "    summary.append({\n",
    "        'Source': name,\n",
    "        'Total_rsIDs': len(rsid_data[name]),\n",
    "        'Resolved': len(bed_df),\n",
    "        'Success_Rate': f\"{len(bed_df)/len(rsid_data[name])*100:.1f}%\",\n",
    "        'Chromosomes': bed_df['chr'].nunique(),\n",
    "        'BED_File': bed_path\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Resolved: {len(bed_df)}/{len(rsid_data[name])}\")\n",
    "    print(f\"  Chromosome distribution:\")\n",
    "    print(bed_df['chr'].value_counts().head(5).to_string())\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1660bbff",
   "metadata": {},
   "source": [
    "## Step 5: Check Overlap with Our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e6f8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset has 390615 SNPs\n",
      "\n",
      "Overlap with known AISNP panels (by chr:pos coordinates):\n",
      "======================================================================\n",
      "\n",
      "forenseq:\n",
      "  Total in panel: 56\n",
      "  Available in our data: 4 (7.1%)\n",
      "  Overlapping rsIDs: ['rs9522149', 'rs11652805', 'rs1834619', 'rs16891982']\n",
      "  Saved overlap BED: /home/Plutonium/Documents/BioinfoMidterm/output/part2/forenseq_overlap.bed\n"
     ]
    }
   ],
   "source": [
    "# Load our SNP coordinates from pfile\n",
    "pvar_file = str(PATHS.PLINK_LD_PRUNED) + '.pvar'\n",
    "\n",
    "if Path(pvar_file).exists():\n",
    "    # Load our SNPs with coordinates\n",
    "    our_snps = []\n",
    "    with open(pvar_file) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) >= 3:\n",
    "                chrom = fields[0]\n",
    "                pos = int(fields[1])\n",
    "                rsid = fields[2]\n",
    "                our_snps.append({'chr': chrom, 'pos': pos, 'rsid': rsid})\n",
    "    \n",
    "    our_snps_df = pd.DataFrame(our_snps)\n",
    "    # Create coordinate set for fast lookup (chr, pos)\n",
    "    our_coords = set(zip(our_snps_df['chr'].astype(str), our_snps_df['pos']))\n",
    "    \n",
    "    print(f\"Our dataset has {len(our_snps_df)} SNPs\")\n",
    "    \n",
    "    # Check overlap for each source by coordinates\n",
    "    print(f\"\\nOverlap with known AISNP panels (by chr:pos coordinates):\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for name, bed_path in bed_files.items():\n",
    "        # Load BED file\n",
    "        bed_df = pd.read_csv(bed_path, sep='\\t', header=None,\n",
    "                             names=['chr', 'start', 'end', 'rsid'])\n",
    "        \n",
    "        # BED uses 0-based start, so end position = 1-based position\n",
    "        # Match using chromosome and end position (1-based coordinate)\n",
    "        bed_df['chr_clean'] = bed_df['chr'].astype(str).str.replace('chr', '')\n",
    "        bed_coords = set(zip(bed_df['chr_clean'], bed_df['end']))\n",
    "        \n",
    "        overlap_coords = bed_coords & our_coords\n",
    "        \n",
    "        # Find the matching rsIDs\n",
    "        overlapping_rsids = bed_df[\n",
    "            bed_df.apply(lambda r: (r['chr_clean'], r['end']) in our_coords, axis=1)\n",
    "        ]['rsid'].tolist()\n",
    "        \n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Total in panel: {len(bed_df)}\")\n",
    "        print(f\"  Available in our data: {len(overlap_coords)} ({len(overlap_coords)/len(bed_df)*100:.1f}%)\")\n",
    "        print(f\"  Overlapping rsIDs: {overlapping_rsids[:10]}{'...' if len(overlapping_rsids) > 10 else ''}\")\n",
    "        \n",
    "        # Save overlapping SNPs for downstream use\n",
    "        if overlapping_rsids:\n",
    "            overlap_df = bed_df[bed_df['rsid'].isin(overlapping_rsids)][['chr', 'start', 'end', 'rsid']]\n",
    "            overlap_path = str(OUTPUT_DIR / f\"{name}_overlap.bed\")\n",
    "            overlap_df.to_csv(overlap_path, sep='\\t', header=False, index=False)\n",
    "            print(f\"  Saved overlap BED: {overlap_path}\")\n",
    "else:\n",
    "    print(f\"pvar file not found: {pvar_file}\")\n",
    "    print(\"Run Part 1 notebooks first to generate LD-pruned pfile.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7107cd3",
   "metadata": {},
   "source": [
    "## Step 6: Save Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "928aa8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved: /home/Plutonium/Documents/BioinfoMidterm/output/part2/rsid_conversion_summary.csv\n",
      "Combined rsIDs saved: /home/Plutonium/Documents/BioinfoMidterm/output/part2/all_known_aisnps.csv\n"
     ]
    }
   ],
   "source": [
    "# Save summary\n",
    "summary_path = str(OUTPUT_DIR / \"rsid_conversion_summary.csv\")\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"Summary saved: {summary_path}\")\n",
    "\n",
    "# Save combined rsID list (all sources)\n",
    "all_rsids = []\n",
    "for name, rsids in rsid_data.items():\n",
    "    for rsid in rsids:\n",
    "        all_rsids.append({'rsid': rsid, 'source': name})\n",
    "\n",
    "all_rsids_df = pd.DataFrame(all_rsids)\n",
    "all_rsids_path = str(OUTPUT_DIR / \"all_known_aisnps.csv\")\n",
    "all_rsids_df.to_csv(all_rsids_path, index=False)\n",
    "print(f\"Combined rsIDs saved: {all_rsids_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01e41f",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8add6f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "rsID TO BED CONVERSION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Sources Processed: 1\n",
      "  - forenseq: Verogen ForenSeq Ancestry SNPs\n",
      "\n",
      "Genome Assembly: GRCh37\n",
      "\n",
      "Output Files:\n",
      "  - forenseq.bed\n",
      "  - forenseq_annotated.csv\n",
      "  - forenseq_rsid_cache.csv (API cache)\n",
      "\n",
      "Next Steps:\n",
      "  1. Run 07_bed_to_ml_matrix.ipynb to create ML matrices\n",
      "  2. Run 08_known_aisnps_ml.ipynb for model comparison\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"rsID TO BED CONVERSION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nSources Processed: {len(available_sources)}\")\n",
    "for source in available_sources:\n",
    "    print(f\"  - {source['name']}: {source['description']}\")\n",
    "\n",
    "print(f\"\\nGenome Assembly: {ASSEMBLY}\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "for name in bed_files.keys():\n",
    "    print(f\"  - {name}.bed\")\n",
    "    print(f\"  - {name}_annotated.csv\")\n",
    "    print(f\"  - {name}_rsid_cache.csv (API cache)\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Run 07_bed_to_ml_matrix.ipynb to create ML matrices\")\n",
    "print(f\"  2. Run 08_known_aisnps_ml.ipynb for model comparison\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneAnalysisET4596E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
