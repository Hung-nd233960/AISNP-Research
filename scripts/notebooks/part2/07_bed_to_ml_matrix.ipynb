{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60c49b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/Plutonium/Documents/BioinfoMidterm\n",
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set project root\n",
    "project_root = Path(\"/home/Plutonium/Documents/BioinfoMidterm\")\n",
    "os.chdir(project_root)\n",
    "sys.path.insert(0, str(project_root / \"scripts\"))\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "# Project imports\n",
    "from config import PATHS\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b7665",
   "metadata": {},
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b610be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input VCF: /home/Plutonium/Documents/BioinfoMidterm/1000genomes/main_vcf/main_vcf.vcf.gz\n",
      "VCF exists: True\n",
      "Samples CSV: 1000genomes/EAS_subpopulation_samples.csv\n",
      "Part 2 directory: /home/Plutonium/Documents/BioinfoMidterm/output/part2\n",
      "\n",
      "Found 1 BED files:\n",
      "  - forenseq.bed\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "PART2_DIR = project_root / \"output\" / \"part2\"\n",
    "PART2_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Input VCF - use the unified SNP-only biallelic VCF\n",
    "INPUT_VCF = project_root / \"1000genomes\" / \"main_vcf\" / \"main_vcf.vcf.gz\"\n",
    "SAMPLES_CSV = str(PATHS.EAS_SAMPLES_CSV)\n",
    "\n",
    "print(f\"Input VCF: {INPUT_VCF}\")\n",
    "print(f\"VCF exists: {INPUT_VCF.exists()}\")\n",
    "print(f\"Samples CSV: {SAMPLES_CSV}\")\n",
    "print(f\"Part 2 directory: {PART2_DIR}\")\n",
    "\n",
    "# List available BED files\n",
    "bed_files = list(PART2_DIR.glob(\"*.bed\"))\n",
    "# Exclude overlap BED files\n",
    "bed_files = [f for f in bed_files if '_overlap' not in f.stem]\n",
    "print(f\"\\nFound {len(bed_files)} BED files:\")\n",
    "for f in bed_files:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d13d5",
   "metadata": {},
   "source": [
    "## Step 1: Load Sample List (EAS subpopulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a162ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 306\n",
      "Population distribution:\n",
      "pop\n",
      "JPT    104\n",
      "CHB    103\n",
      "KHV     99\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample list saved: /home/Plutonium/Documents/BioinfoMidterm/output/part2/eas_samples.txt\n"
     ]
    }
   ],
   "source": [
    "# Load sample info (CSV has no header: sample, pop, super_pop)\n",
    "samples_df = pd.read_csv(SAMPLES_CSV, header=None, names=['sample', 'pop', 'super_pop'])\n",
    "print(f\"Total samples: {len(samples_df)}\")\n",
    "print(f\"Population distribution:\")\n",
    "print(samples_df['pop'].value_counts())\n",
    "\n",
    "# Create sample list file for bcftools\n",
    "sample_list_file = str(PART2_DIR / \"eas_samples.txt\")\n",
    "samples_df['sample'].to_csv(sample_list_file, index=False, header=False)\n",
    "print(f\"\\nSample list saved: {sample_list_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c336f17",
   "metadata": {},
   "source": [
    "## Step 2: Extract VCF for Each AISNP Panel using bcftools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65069312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Processing: forenseq\n",
      "======================================================================\n",
      "Running: bcftools view -R /home/Plutonium/Documents/BioinfoMidterm/output/part2/forenseq.bed -S /home/Plutonium/Documents/BioinfoMidterm/output/part2/eas_samples.txt -O v -o /home/Plutonium/Documents/BioinfoMidterm/output/part2/forenseq_extracted.vcf /home/Plutonium/Documents/BioinfoMidterm/1000genomes/main_vcf/main_vcf.vcf.gz\n",
      "Error: [E::hts_open_format] Failed to open file \"/home/Plutonium/Documents/BioinfoMidterm/1000genomes/main_vcf/main_vcf.vcf.gz\" : No such file or directory\n",
      "Failed to read from /home/Plutonium/Documents/BioinfoMidterm/1000genomes/main_vcf/main_vcf.vcf.gz: No such file or directory\n",
      "\n",
      "\n",
      "\n",
      "Extracted VCFs for 0 sources\n"
     ]
    }
   ],
   "source": [
    "# Extract VCF for each BED file using bcftools\n",
    "extracted_vcfs = {}\n",
    "\n",
    "for bed_file in bed_files:\n",
    "    source_name = bed_file.stem\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing: {source_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    output_vcf = str(PART2_DIR / f\"{source_name}_extracted.vcf\")\n",
    "    \n",
    "    # bcftools view:\n",
    "    # -R: regions from BED file\n",
    "    # -S: samples to include\n",
    "    # -O v: output VCF format\n",
    "    cmd = [\n",
    "        \"bcftools\", \"view\",\n",
    "        \"-R\", str(bed_file),\n",
    "        \"-S\", sample_list_file,\n",
    "        \"-O\", \"v\",\n",
    "        \"-o\", output_vcf,\n",
    "        str(INPUT_VCF)\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running: {' '.join(cmd)}\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "        continue\n",
    "    \n",
    "    # Count variants in output\n",
    "    count_cmd = [\"grep\", \"-c\", \"-v\", \"^#\", output_vcf]\n",
    "    count_result = subprocess.run(count_cmd, capture_output=True, text=True)\n",
    "    n_variants = int(count_result.stdout.strip()) if count_result.returncode == 0 else 0\n",
    "    \n",
    "    print(f\"Extracted {n_variants} variants\")\n",
    "    extracted_vcfs[source_name] = output_vcf\n",
    "\n",
    "print(f\"\\n\\nExtracted VCFs for {len(extracted_vcfs)} sources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806623c6",
   "metadata": {},
   "source": [
    "## Step 3: Convert VCF to Genotype Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba14cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Converting: forenseq\n",
      "==================================================\n",
      "Shape: (306, 2) (0 SNPs)\n",
      "Population distribution:\n",
      "pop\n",
      "JPT    104\n",
      "CHB    103\n",
      "KHV     99\n",
      "Name: count, dtype: int64\n",
      "Saved: /home/Plutonium/Documents/BioinfoMidterm/output/part2/forenseq_ml_matrix.csv\n",
      "\n",
      "\n",
      "Converted 1 sources to ML matrices\n"
     ]
    }
   ],
   "source": [
    "def vcf_to_genotype_matrix(vcf_path: str, samples_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert VCF to genotype matrix (samples x SNPs) using bcftools.\n",
    "    Genotypes encoded as 0, 1, 2 (count of ALT alleles).\n",
    "    \n",
    "    Uses bcftools query for speed and accuracy.\n",
    "    \"\"\"\n",
    "    # Step 1: Get sample IDs from VCF using bcftools\n",
    "    sample_cmd = [\"bcftools\", \"query\", \"-l\", vcf_path]\n",
    "    sample_result = subprocess.run(sample_cmd, capture_output=True, text=True, check=True)\n",
    "    sample_ids = sample_result.stdout.strip().split('\\n')\n",
    "    \n",
    "    # Step 2: Extract genotypes using bcftools query\n",
    "    # Format: CHROM, POS, ID, then GT for each sample\n",
    "    query_cmd = [\n",
    "        \"bcftools\", \"query\",\n",
    "        \"-f\", \"%CHROM\\t%POS\\t%ID[\\t%GT]\\n\",\n",
    "        vcf_path\n",
    "    ]\n",
    "    query_result = subprocess.run(query_cmd, capture_output=True, text=True, check=True)\n",
    "    \n",
    "    # Parse the output\n",
    "    genotypes = {}\n",
    "    \n",
    "    for line in query_result.stdout.strip().split('\\n'):\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        fields = line.split('\\t')\n",
    "        chrom = fields[0]\n",
    "        pos = fields[1]\n",
    "        rsid = fields[2]\n",
    "        \n",
    "        # Use rsid if available, else chr:pos\n",
    "        snp_id = rsid if rsid != '.' else f\"{chrom}:{pos}\"\n",
    "        \n",
    "        # Parse genotypes (starting from field 3)\n",
    "        gt_values = []\n",
    "        for gt in fields[3:]:\n",
    "            if gt in ['./.', '.|.', '.']:\n",
    "                gt_values.append(np.nan)\n",
    "            else:\n",
    "                # Count ALT alleles (handle both | and / separators)\n",
    "                alleles = gt.replace('|', '/').split('/')\n",
    "                alt_count = sum(1 for a in alleles if a != '0' and a != '.')\n",
    "                gt_values.append(alt_count)\n",
    "        \n",
    "        genotypes[snp_id] = gt_values\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(genotypes, index=sample_ids)\n",
    "    df.index.name = 'sample'\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Add population labels\n",
    "    df = df.merge(samples_df[['sample', 'pop']], on='sample', how='left')\n",
    "    \n",
    "    # Reorder columns: sample, pop, then SNPs\n",
    "    snp_cols = [c for c in df.columns if c not in ['sample', 'pop']]\n",
    "    df = df[['sample', 'pop'] + snp_cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Convert each extracted VCF to matrix\n",
    "ml_matrices = {}\n",
    "\n",
    "for source_name, vcf_path in extracted_vcfs.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Converting: {source_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    df = vcf_to_genotype_matrix(vcf_path, samples_df)\n",
    "    \n",
    "    n_snps = len([c for c in df.columns if c not in ['sample', 'pop']])\n",
    "    print(f\"Shape: {df.shape} ({n_snps} SNPs)\")\n",
    "    print(f\"Population distribution:\")\n",
    "    print(df['pop'].value_counts())\n",
    "    \n",
    "    # Save matrix\n",
    "    output_path = str(PART2_DIR / f\"{source_name}_ml_matrix.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "    \n",
    "    ml_matrices[source_name] = df\n",
    "\n",
    "print(f\"\\n\\nConverted {len(ml_matrices)} sources to ML matrices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442290b9",
   "metadata": {},
   "source": [
    "## Step 4: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f3bef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXTRACTION SUMMARY\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>SNPs</th>\n",
       "      <th>Samples</th>\n",
       "      <th>VCF</th>\n",
       "      <th>Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forenseq</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>forenseq_extracted.vcf</td>\n",
       "      <td>forenseq_ml_matrix.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Source  SNPs  Samples                     VCF                  Matrix\n",
       "0  forenseq     0      306  forenseq_extracted.vcf  forenseq_ml_matrix.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary saved: /home/Plutonium/Documents/BioinfoMidterm/output/part2/extraction_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Display summary\n",
    "extraction_summary = []\n",
    "\n",
    "for source_name, df in ml_matrices.items():\n",
    "    n_snps = len([c for c in df.columns if c not in ['sample', 'pop']])\n",
    "    extraction_summary.append({\n",
    "        'Source': source_name,\n",
    "        'SNPs': n_snps,\n",
    "        'Samples': len(df),\n",
    "        'VCF': f\"{source_name}_extracted.vcf\",\n",
    "        'Matrix': f\"{source_name}_ml_matrix.csv\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(extraction_summary)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EXTRACTION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "display(summary_df)\n",
    "\n",
    "# Save summary\n",
    "summary_path = str(PART2_DIR / \"extraction_summary.csv\")\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(f\"\\nSummary saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d37212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "forenseq\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG01595</td>\n",
       "      <td>KHV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG01596</td>\n",
       "      <td>KHV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG01597</td>\n",
       "      <td>KHV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample  pop\n",
       "0  HG01595  KHV\n",
       "1  HG01596  KHV\n",
       "2  HG01597  KHV"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preview each matrix\n",
    "for name, df in ml_matrices.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4151a6",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad15f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BED TO ML MATRIX CONVERSION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Workflow completed:\n",
      "  1. BED files → bcftools extract → VCF (variants + samples)\n",
      "  2. VCF → Genotype matrix (samples × SNPs)\n",
      "\n",
      "ML matrices created for 1 AISNP panels:\n",
      "  - forenseq\n",
      "\n",
      "Output files saved to: /home/Plutonium/Documents/BioinfoMidterm/output/part2\n",
      "\n",
      "Next Steps:\n",
      "  Run 08_known_aisnps_ml.ipynb to train and evaluate models\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"BED TO ML MATRIX CONVERSION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nWorkflow completed:\")\n",
    "print(f\"  1. BED files → bcftools extract → VCF (variants + samples)\")\n",
    "print(f\"  2. VCF → Genotype matrix (samples × SNPs)\")\n",
    "\n",
    "print(f\"\\nML matrices created for {len(ml_matrices)} AISNP panels:\")\n",
    "for name in ml_matrices.keys():\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "print(f\"\\nOutput files saved to: {PART2_DIR}\")\n",
    "\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  Run 08_known_aisnps_ml.ipynb to train and evaluate models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneAnalysisET4596E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
